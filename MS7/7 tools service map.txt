│   .env
│   [
│       # Django's main secret key
│       DJANGO_SECRET_KEY='django-insecure-m3x$8o#H45Ysdverg56564ldpcuck6bytc4h1*8v!=8(_wau6g8or'
│       JWT_SECRET_KEY ='jwt-secure-m3x$DFGRTJRTYNEHRETNEFDDHD43.m<?><DFGRTJYRJGc4h1*8v!=8(_wau6g8or'
│       # You can also add other environment-specific settings here
│       DJANGO_DEBUG='True'
│       DATABASE_URL='sqlite:///./db.sqlite3' # Example for database config
│       JWT_ISSUER="https://ms1.auth-service.com"
│       RABBITMQ_URL='amqp://guest:guest@localhost:5672/'
│       NODE_SERVICE_URL='http://localhost:8003'
│       
│   ]
├───MS7
│   __init__.py
│   [
│       
│   ]
│   asgi.py
│   [
│       """
│       ASGI config for MS7 project.
│       
│       It exposes the ASGI callable as a module-level variable named ``application``.
│       
│       For more information on this file, see
│       https://docs.djangoproject.com/en/5.2/howto/deployment/asgi/
│       """
│       
│       import os
│       
│       from django.core.asgi import get_asgi_application
│       
│       os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'MS7.settings')
│       
│       application = get_asgi_application()
│       
│   ]
│   settings.py
│   [
│       
│       from datetime import timedelta
│       import os
│       from pathlib import Path
│       from datetime import timedelta
│       # Build paths inside the project like this: BASE_DIR / 'subdir'.
│       BASE_DIR = Path(__file__).resolve().parent.parent
│       from datetime import timedelta
│       
│       from dotenv import load_dotenv
│       load_dotenv(BASE_DIR / '.env')
│       # Quick-start development settings - unsuitable for production
│       # See https://docs.djangoproject.com/en/5.2/howto/deployment/checklist/
│       
│       SECRET_KEY = os.getenv('DJANGO_SECRET_KEY')
│       # REST Framework
│       JWT_SECRET_KEY = os.getenv('JWT_SECRET_KEY')
│       if not SECRET_KEY:
│           # This fallback should ideally not be hit if .env is loaded correctly
│           # or if the environment variable is set directly in the deployment environment.
│           SECRET_KEY = 'django-insecure-fallback-dev-key-!!change-me!!'
│           print("WARNING: DJANGO_SECRET_KEY not found in environment or .env. Using fallback. THIS IS INSECURE FOR PRODUCTION.")
│       
│       DEBUG = os.getenv('DJANGO_DEBUG', 'True').lower() in ('true', '1', 't')
│       
│       ALLOWED_HOSTS = ['*']
│       
│       
│       # Application definition
│       
│       INSTALLED_APPS = [
│       
│       
│           'django.contrib.admin',
│           'django.contrib.auth',
│           'django.contrib.contenttypes',
│           'django.contrib.sessions',
│           'django.contrib.messages',
│           'django.contrib.staticfiles',
│           'rest_framework',
│           'rest_framework_simplejwt',
│           'rest_framework.authtoken',
│           'tools',
│           'tools_internals',
│           'messaging',
│       ]
│       
│       MIDDLEWARE = [
│           'django.middleware.security.SecurityMiddleware',
│           'django.contrib.sessions.middleware.SessionMiddleware',
│           'django.middleware.common.CommonMiddleware',
│           'django.middleware.csrf.CsrfViewMiddleware',
│           'django.contrib.auth.middleware.AuthenticationMiddleware',
│           'django.contrib.messages.middleware.MessageMiddleware',
│           'django.middleware.clickjacking.XFrameOptionsMiddleware',
│       ]
│       
│       ROOT_URLCONF = 'MS7.urls'
│       
│       TEMPLATES = [
│           {
│               'BACKEND': 'django.template.backends.django.DjangoTemplates',
│               'DIRS': [],
│               'APP_DIRS': True,
│               'OPTIONS': {
│                   'context_processors': [
│                       'django.template.context_processors.request',
│                       'django.contrib.auth.context_processors.auth',
│                       'django.contrib.messages.context_processors.messages',
│                   ],
│               },
│           },
│       ]
│       
│       WSGI_APPLICATION = 'MS7.wsgi.application'
│       
│       
│       # Database
│       # https://docs.djangoproject.com/en/5.2/ref/settings/#databases
│       
│       DATABASES = {
│           'default': {
│               'ENGINE': 'django.db.backends.sqlite3',
│               'NAME': BASE_DIR / 'db.sqlite3',
│           }
│       }
│       
│       
│       # Password validation
│       # https://docs.djangoproject.com/en/5.2/ref/settings/#auth-password-validators
│       
│       AUTH_PASSWORD_VALIDATORS = [
│           {
│               'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
│           },
│           {
│               'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
│           },
│           {
│               'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
│           },
│           {
│               'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
│           },
│       ]
│       
│       
│       # Internationalization
│       # https://docs.djangoproject.com/en/5.2/topics/i18n/
│       
│       LANGUAGE_CODE = 'en-us'
│       
│       TIME_ZONE = 'UTC'
│       
│       USE_I18N = True
│       
│       USE_TZ = True
│       
│       
│       # Static files (CSS, JavaScript, Images)
│       # https://docs.djangoproject.com/en/5.2/howto/static-files/
│       
│       STATIC_URL = '/static/'
│       STATIC_ROOT = BASE_DIR / 'staticfiles'
│       
│       # Default primary key field type
│       # https://docs.djangoproject.com/en/5.2/ref/settings/#default-auto-field
│       
│       DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'
│       
│       
│       
│       
│       
│       
│       # REST Framework
│       REST_FRAMEWORK = {
│           "DEFAULT_PERMISSION_CLASSES": ["rest_framework.permissions.IsAuthenticated"],
│           "DEFAULT_AUTHENTICATION_CLASSES": (
│                    
│               "tools.custom_auth.ForceTokenUserJWTAuthentication", # <<< YOUR CUSTOM AUTH CLASS
│           ),
│           'DEFAULT_THROTTLE_CLASSES': (
│               'rest_framework.throttling.AnonRateThrottle',
│               'rest_framework.throttling.UserRateThrottle'
│           ),
│           'DEFAULT_THROTTLE_RATES': {
│               'anon': '100/day',  # Adjust as needed for unauthenticated requests
│               'user': '20000/day' # Adjust as needed for authenticated requests
│           }
│       }
│       
│       SIMPLE_JWT = {
│       
│           "SIGNING_KEY": JWT_SECRET_KEY,  # <<< USE DJANGO'S SECRET_KEY LOADED FROM ENV
│           "VERIFYING_KEY": JWT_SECRET_KEY,
│           "ISSUER": os.getenv('JWT_ISSUER', "https://ms1.auth-service.com"), # MUST match MS1's issuer
│           "AUTH_HEADER_TYPES": ("Bearer",),
│           "ACCESS_TOKEN_LIFETIME": timedelta(minutes=60), # e.g., 1 hour
│           "REFRESH_TOKEN_LIFETIME": timedelta(days=1),    # e.g., 1 day
│           "LEEWAY": timedelta(seconds=10),
│           "ALGORITHM": "HS256",
│           
│           # --- Settings related to interpreting the token payload ---
│           """
│       "USER_ID_CLAIM": "user_id": (Your Specific Question)
│        This is a critical instruction. It tells simple-jwt:
│          "When you parse the token's payload (the data inside),
│            the claim that contains the user's primary identifier is named 'user_id'."
│              Your MS1's CustomTokenObtainPairSerializer probably adds a claim with this name.
│           """
│       
│           "USER_ID_CLAIM": "user_id",
│       
│           "USER_ID_FIELD": "id",
│           "TOKEN_USER_CLASS": "rest_framework_simplejwt.models.TokenUser", # Explicitly use TokenUse
│       
│           # --- Settings for features MS2 likely DOES NOT use ---
│           "UPDATE_LAST_LOGIN": False,
│           "ROTATE_REFRESH_TOKENS": False,
│           "BLACKLIST_AFTER_ROTATION": False, 
│       
│       }
│       
│       
│       RABBITMQ_URL = os.getenv('RABBITMQ_URL', 'amqp://guest:guest@localhost:5672/')
│       
│       NODE_SERVICE_URL= os.getenv('NODE_SERVICE_URL', 'http://localhost:8003')
│   ]
│   urls.py
│   [
│       from django.contrib import admin
│       from django.urls import path, include
│       
│       urlpatterns = [
│           # Public API for users
│           path('ms7/api/v1/', include('tools.api_urls')),
│       
│           # Internal HTTP API for other services (like Node Service)
│           path('ms7/internal/v1/', include('tools_internals.internal_urls')),
│       
│           # Django admin
│           path('ms7/admin/', admin.site.urls),
│       ]
│   ]
│   wsgi.py
│   [
│       """
│       WSGI config for MS7 project.
│       
│       It exposes the WSGI callable as a module-level variable named ``application``.
│       
│       For more information on this file, see
│       https://docs.djangoproject.com/en/5.2/howto/deployment/wsgi/
│       """
│       
│       import os
│       
│       from django.core.wsgi import get_wsgi_application
│       
│       os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'MS7.settings')
│       
│       application = get_wsgi_application()
│       
│   ]
│   db.sqlite3
│   [
│       [Binary file - content not shown]
│   ]
│   manage.py
│   [
│       #!/usr/bin/env python
│       """Django's command-line utility for administrative tasks."""
│       import os
│       import sys
│       
│       
│       def main():
│           """Run administrative tasks."""
│           os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'MS7.settings')
│           try:
│               from django.core.management import execute_from_command_line
│           except ImportError as exc:
│               raise ImportError(
│                   "Couldn't import Django. Are you sure it's installed and "
│                   "available on your PYTHONPATH environment variable? Did you "
│                   "forget to activate a virtual environment?"
│               ) from exc
│           execute_from_command_line(sys.argv)
│       
│       
│       if __name__ == '__main__':
│           main()
│       
│   ]
│   project meta gen.py
│   [
│       import os
│       import mimetypes
│       import glob
│       import re
│       
│       def get_next_sequence_number():
│           """Find the next available sequence number for the output file."""
│           script_dir = os.path.abspath(os.path.dirname(__file__))
│           pattern = os.path.join(script_dir, "project_structure_*.txt")
│           existing_files = glob.glob(pattern)
│           
│           if not existing_files:
│               return 1
│           
│           # Extract sequence numbers from existing files
│           sequence_numbers = []
│           for file_path in existing_files:
│               basename = os.path.basename(file_path)
│               match = re.search(r'project_structure_(\d+)\.txt', basename)
│               if match:
│                   sequence_numbers.append(int(match.group(1)))
│           
│           if not sequence_numbers:
│               return 1
│           
│           # Return the next number in sequence
│           return max(sequence_numbers) + 1
│       
│       def generate_project_structure():
│           """Generate a text file containing the project structure with file contents."""
│           # Get the absolute path of the script's directory
│           script_dir = os.path.abspath(os.path.dirname(__file__))
│           # Change to that directory to ensure we're working only there
│           os.chdir(script_dir)
│           
│           # Generate a unique filename with sequence number
│           seq_num = get_next_sequence_number()
│           output_file = os.path.join(script_dir, f"project_structure_{seq_num}.txt")
│           
│           with open(output_file, 'w', encoding='utf-8', errors='replace') as f:
│               # Get items in the script directory only, excluding specified patterns
│               items = get_directory_items(script_dir, output_file)
│               
│               # Process each item at root level
│               for i, item in enumerate(items):
│                   is_last = i == len(items) - 1
│                   
│                   if os.path.isdir(os.path.join(script_dir, item)):
│                       # It's a directory
│                       if is_last:
│                           f.write(f"└───{item}\n")
│                           process_directory(os.path.join(script_dir, item), f, "    ", output_file, script_dir)
│                       else:
│                           f.write(f"├───{item}\n")
│                           process_directory(os.path.join(script_dir, item), f, "│   ", output_file, script_dir)
│                   else:
│                       # It's a file - at root level, format as in the example
│                       f.write(f"│   {item}\n")
│                       # Include file content
│                       content = read_file_content(os.path.join(script_dir, item))
│                       f.write(f"│   [\n")
│                       content_lines = content.split('\n')
│                       for line in content_lines:
│                           f.write(f"│       {line}\n")
│                       f.write(f"│   ]\n")
│           
│           print(f"Project structure has been written to {output_file}")
│       
│       def should_exclude(item_path):
│           """Check if an item should be excluded based on patterns."""
│           # Exclude __pycache__ directories
│           if os.path.isdir(item_path) and "__pycache__" in item_path:
│               return True
│           
│           # Exclude migrations directories
│           if os.path.isdir(item_path) and "migrations" in item_path:
│               return True
│           
│           # Exclude .pyc files
│           if item_path.endswith('.pyc'):
│               return True
│           
│           # Exclude all project_structure files
│           if os.path.basename(item_path).startswith("project_structure_") and item_path.endswith(".txt"):
│               return True
│           
│           return False
│       
│       def get_directory_items(dir_path, output_file):
│           """Get sorted list of items in a directory, excluding the output file and specified patterns."""
│           # Get absolute path to output file to exclude it
│           abs_output_path = os.path.abspath(output_file)
│           
│           try:
│               # List directory contents
│               items = sorted(os.listdir(dir_path))
│               
│               # Filter out the output file itself and items matching exclude patterns
│               filtered_items = []
│               for item in items:
│                   item_path = os.path.join(dir_path, item)
│                   
│                   # Skip the output file
│                   if os.path.abspath(item_path) == abs_output_path:
│                       continue
│                       
│                   # Skip symlinks that might point outside
│                   if os.path.islink(item_path):
│                       continue
│                       
│                   # Skip items matching exclude patterns
│                   if should_exclude(item_path):
│                       continue
│                       
│                   filtered_items.append(item)
│               
│               return filtered_items
│           except Exception as e:
│               print(f"Error listing directory {dir_path}: {e}")
│               return []
│       
│       def is_binary_file(file_path):
│           """Determine if a file is binary or text."""
│           # Initialize mimetypes
│           if not mimetypes.inited:
│               mimetypes.init()
│           
│           # Check by mime type first
│           mime_type, _ = mimetypes.guess_type(file_path)
│           if mime_type and not mime_type.startswith(('text/', 'application/json', 'application/xml', 'application/javascript')):
│               return True
│               
│           # Fallback: check for null bytes
│           try:
│               with open(file_path, 'rb') as f:
│                   chunk = f.read(4096)
│                   return b'\0' in chunk
│           except Exception:
│               return True  # If we can't read it, assume binary
│       
│       def read_file_content(file_path, max_length=500000):
│           """Read content from a file, handling binary files and errors."""
│           try:
│               # Check if binary
│               if is_binary_file(file_path):
│                   return "[Binary file - content not shown]"
│                   
│               # Read text file
│               with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
│                   content = f.read(max_length + 1)
│                   
│               # Handle truncation
│               if len(content) > max_length:
│                   content = content[:max_length] + "... [truncated]"
│                   
│               # Return raw content without escaping special characters
│               return content
│           except Exception as e:
│               return f"[Error reading file: {str(e)}]"
│       
│       def process_directory(dir_path, file_obj, indent, output_file, script_dir):
│           """Recursively process a directory and write its structure to the file."""
│           # Safety check - ensure we're still within the script directory
│           rel_path = os.path.relpath(dir_path, script_dir)
│           if rel_path.startswith('..') or rel_path == '.':
│               return  # Don't process if it's outside our script directory
│           
│           try:
│               # List directory contents
│               items = get_directory_items(dir_path, output_file)
│               
│               # Process each item
│               for i, item in enumerate(items):
│                   item_path = os.path.join(dir_path, item)
│                   is_last = i == len(items) - 1
│                   
│                   # Safety check - don't follow symlinks or items outside our script directory
│                   if os.path.islink(item_path):
│                       continue
│                       
│                   rel_path = os.path.relpath(item_path, script_dir)
│                   if rel_path.startswith('..'):
│                       continue
│                   
│                   if os.path.isdir(item_path):
│                       # It's a directory
│                       if is_last:
│                           file_obj.write(f"{indent}└───{item}\n")
│                           process_directory(item_path, file_obj, indent + "    ", output_file, script_dir)
│                       else:
│                           file_obj.write(f"{indent}├───{item}\n")
│                           process_directory(item_path, file_obj, indent + "│   ", output_file, script_dir)
│                   else:
│                       # It's a file
│                       file_obj.write(f"{indent}{item}\n")
│                       # Include file content
│                       content = read_file_content(item_path)
│                       file_obj.write(f"{indent}[\n")
│                       content_lines = content.split('\n')
│                       for line in content_lines:
│                           file_obj.write(f"{indent}    {line}\n")
│                       file_obj.write(f"{indent}]\n")
│           except PermissionError:
│               file_obj.write(f"{indent}[Permission denied]\n")
│           except Exception as e:
│               file_obj.write(f"{indent}[Error: {str(e)}]\n")
│       
│       if __name__ == "__main__":
│           generate_project_structure()
│   ]
│   requirements.txt
│   [
│       asgiref==3.9.1
│       certifi==2025.7.14
│       cffi==1.17.1
│       charset-normalizer==3.4.2
│       cryptography==45.0.5
│       defusedxml==0.7.1
│       Django==5.2.4
│       djangorestframework==3.16.0
│       djangorestframework_simplejwt==5.5.1
│       djoser==2.3.3
│       idna==3.10
│       oauthlib==3.3.1
│       pycparser==2.22
│       PyJWT==2.10.1
│       python3-openid==3.2.0
│       requests==2.32.4
│       requests-oauthlib==2.0.0
│       social-auth-app-django==5.5.1
│       social-auth-core==4.7.0
│       sqlparse==0.5.3
│       tzdata==2025.2
│       urllib3==2.5.0
│       pika 
│       httpx 
│       grpcio
│       grpcio-tools
│       protobuf
│       google-api-python-client
│   ]
├───tools
│   __init__.py
│   [
│       
│   ]
│   admin.py
│   [
│       from django.contrib import admin
│       from .models import Tool, ToolType
│       # Register your models here.
│       admin.site.register(Tool)
│       #admin.site.register(ToolType)
│   ]
│   api_urls.py
│   [
│       from django.urls import path
│       from .views import ToolListCreateAPIView, ToolDetailAPIView
│       
│       urlpatterns = [
│           path('tools/', ToolListCreateAPIView.as_view(), name='tool-list-create'),
│           path('tools/<uuid:pk>/', ToolDetailAPIView.as_view(), name='tool-detail'),
│       ]
│   ]
│   apps.py
│   [
│       from django.apps import AppConfig
│       
│       
│       class ToolsConfig(AppConfig):
│           default_auto_field = 'django.db.models.BigAutoField'
│           name = 'tools'
│       
│   ]
│   custom_auth.py
│   [
│       # MS2/products/custom_auth.py
│       from rest_framework_simplejwt.authentication import JWTAuthentication
│       from rest_framework_simplejwt.models import TokenUser # Import TokenUser
│       from rest_framework_simplejwt.settings import api_settings as simple_jwt_settings
│       from django.utils.translation import gettext_lazy as _
│       from rest_framework_simplejwt.exceptions import InvalidToken
│       
│       class ForceTokenUserJWTAuthentication(JWTAuthentication):
│           def get_user(self, validated_token):
│               """
│               Returns a TokenUser instance based on the validated token.
│               Bypasses any local database User lookup for JWT authentication.
│               """
│               try:
│                   # simple_jwt_settings.USER_ID_CLAIM refers to what you set in settings.py
│                   # e.g., "user_id"
│                   user_id = validated_token[simple_jwt_settings.USER_ID_CLAIM]
│               except KeyError:
│                   raise InvalidToken(_("Token contained no recognizable user identification"))
│       
│               # Correct way to instantiate TokenUser: pass the validated_token
│               # The TokenUser class will internally use USER_ID_CLAIM and USER_ID_FIELD
│               # from your SIMPLE_JWT settings to extract the user ID and set its 'id' or 'pk'.
│               token_user = TokenUser(validated_token)
│       
│               # The TokenUser's 'id' (and 'pk') attribute should now be populated correctly
│               # by its own __init__ method based on the validated_token and your SIMPLE_JWT settings
│               # for USER_ID_CLAIM and USER_ID_FIELD.
│       
│               # Example: If you wanted to verify or access it (not strictly necessary here)
│               # print(f"TokenUser ID: {token_user.id}, TokenUser PK: {token_user.pk}")
│       
│               return token_user
│   ]
│   executor.py
│   [
│       import httpx
│       import importlib
│       import json
│       from concurrent.futures import ThreadPoolExecutor, as_completed
│       from .models import Tool
│       
│       class ToolExecutor:
│           """
│           Handles the dynamic execution of tools based on their definition.
│           This class is the single point of entry for running any tool.
│           """
│           def _execute_internal_function(self, pointer: str, arguments: dict):
│               try:
│                   module_name, func_name = pointer.rsplit('.', 1)
│                   module = importlib.import_module(module_name)
│                   func_to_execute = getattr(module, func_name)
│                   return func_to_execute(**arguments)
│               except (ImportError, AttributeError) as e:
│                   raise RuntimeError(f"Could not find or import internal function: {pointer}. Error: {e}")
│       
│           def _execute_webhook(self, config: dict, arguments: dict):
│               url = config.get("url")
│               if not url:
│                   raise ValueError("Webhook execution config is missing 'url'.")
│               
│               # Simple bearer token auth for now; can be expanded.
│               headers = {"Content-Type": "application/json"}
│               auth_config = config.get("authentication")
│               if auth_config and auth_config.get("type") == "bearer":
│                   # In production, this key would be fetched from a secure vault.
│                   token = auth_config.get("token") 
│                   headers["Authorization"] = f"Bearer {token}"
│                   
│               with httpx.Client(timeout=10.0) as client:
│                   try:
│                       response = client.post(url, json=arguments)
│                       response.raise_for_status() # Raise an exception for 4xx/5xx responses
│                       return response.json()
│                   except httpx.RequestError as e:
│                       raise RuntimeError(f"Error calling webhook {url}: {e}")
│       
│           def execute_single_tool(self, tool_call: dict) -> dict:
│               """Executes one tool call and returns the result."""
│               tool_name = tool_call.get("name")
│               arguments = tool_call.get("arguments", {})
│       
│               try:
│                   tool = Tool.objects.get(name=tool_name) # Assuming user is already authorized
│                   execution_config = tool.definition.get("execution", {})
│                   exec_type = execution_config.get("type")
│       
│                   if exec_type == "internal_function":
│                       result_content = self._execute_internal_function(execution_config.get("pointer"), arguments)
│                   elif exec_type == "webhook":
│                       result_content = self._execute_webhook(execution_config, arguments)
│                   else:
│                       raise ValueError(f"Unknown execution type for tool '{tool_name}': {exec_type}")
│       
│                   return {
│                       "tool_call_id": tool_call.get("id"),
│                       "name": tool_name,
│                       "status": "success",
│                       "output": json.dumps(result_content) # Ensure output is a JSON string
│                   }
│               except Exception as e:
│                   return {
│                       "tool_call_id": tool_call.get("id"),
│                       "name": tool_name,
│                       "status": "error",
│                       "output": str(e)
│                   }
│       
│           def execute_parallel_tools(self, tool_calls: list[dict]) -> list[dict]:
│               """
│               Executes a list of tool calls in parallel using a thread pool.
│               This is the primary method used by the gRPC servicer.
│               """
│               results = []
│               with ThreadPoolExecutor() as executor:
│                   future_to_call = {executor.submit(self.execute_single_tool, call): call for call in tool_calls}
│                   for future in as_completed(future_to_call):
│                       try:
│                           result = future.result()
│                           results.append(result)
│                       except Exception as e:
│                           # This catches errors within the future execution itself
│                           call = future_to_call[future]
│                           results.append({
│                               "tool_call_id": call.get("id"),
│                               "name": call.get("name"),
│                               "status": "error",
│                               "output": f"An unexpected execution error occurred: {e}"
│                           })
│               return results
│       
│       # A single instance to be used by the gRPC servicer
│       tool_executor = ToolExecutor()
│   ]
│   ├───mcp_tools
│   │   __init__.py
│   │   [
│   │       
│   │   ]
│   │   discovery.py
│   │   [
│   │       from tools.models import Tool, ToolType
│   │       from django.db import models
│   │       
│   │       def discover_contextual_tools(query: str, user_id: str, tool_ids: list[str] = None) -> list[dict]:
│   │           """
│   │           Implements the MCP logic. Searches the database for relevant tools
│   │           and optionally filters by a list of specified tool IDs.
│   │           """
│   │           print(f"EXECUTING MCP TOOL: discover_contextual_tools with query='{query}'")
│   │           
│   │           # Base query: Find all standard tools the user has access to (system + their own)
│   │           base_queryset = Tool.objects.filter(
│   │               models.Q(is_system_tool=True) | models.Q(owner_id=user_id),
│   │               tool_type=ToolType.STANDARD
│   │           )
│   │       
│   │           # If the user specified specific tools in an MCP node, filter by them.
│   │           if tool_ids:
│   │               final_queryset = base_queryset.filter(id__in=tool_ids)
│   │           else:
│   │               # If no specific tools are requested, perform discovery based on the query.
│   │               # This is where a vector search on `definition['description']` would be ideal.
│   │               # For now, we simulate a simple keyword search.
│   │               final_queryset = base_queryset.filter(definition__description__icontains=query)
│   │       
│   │           # Return the public-facing definitions of the found tools
│   │           return [tool.definition for tool in final_queryset]
│   │   ]
│   models.py
│   [
│       import uuid
│       from django.db import models
│       
│       class ToolType(models.TextChoices):
│           STANDARD = 'standard', 'Standard'
│           MCP = 'mcp', 'Model Context Protocol'
│       
│       class Tool(models.Model):
│           id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
│           name = models.CharField(max_length=255, help_text="Unique, programmatic name, e.g., 'get_current_weather'.")
│           is_system_tool = models.BooleanField(default=False, db_index=True)
│           owner_id = models.UUIDField(db_index=True, null=True, blank=True, help_text="NULL for system tools.")
│           tool_type = models.CharField(max_length=20, choices=ToolType.choices, default=ToolType.STANDARD)
│           definition = models.JSONField(help_text="The tool's complete definition, including its schema and execution details.")
│           created_at = models.DateTimeField(auto_now_add=True)
│           updated_at = models.DateTimeField(auto_now=True)
│       
│           class Meta:
│               unique_together = ('owner_id', 'name')
│               ordering = ['-is_system_tool', 'name']
│       
│           def __str__(self):
│               return f"{self.name} ({self.tool_type})"
│   ]
│   permissions.py
│   [
│       from rest_framework import permissions
│       
│       class IsOwner(permissions.BasePermission):
│           """
│           Custom permission to only allow owners of a tool to edit or delete it.
│           """
│           def has_object_permission(self, request, view, obj):
│               # Read permissions are allowed for any request,
│               # so we'll always allow GET, HEAD or OPTIONS requests.
│               if request.method in permissions.SAFE_METHODS:
│                   return True
│       
│               # Write permissions are only allowed to the owner of the tool.
│               # Ensure we're comparing string versions to avoid UUID object issues.
│               return str(obj.owner_id) == str(request.user.id)
│   ]
│   serializers.py
│   [
│       from rest_framework import serializers
│       from .models import Tool
│       
│       class ToolSerializer(serializers.ModelSerializer):
│           """
│           General purpose serializer for reading and listing tools.
│           """
│           owner_id = serializers.UUIDField(read_only=True)
│       
│           class Meta:
│               model = Tool
│               fields = [
│                   'id', 'name', 'tool_type', 'definition',
│                   'is_system_tool', 'owner_id', 'created_at', 'updated_at'
│               ]
│               read_only_fields = ['id', 'is_system_tool', 'owner_id', 'created_at', 'updated_at']
│       
│       class ToolCreateSerializer(serializers.ModelSerializer):
│           """
│           Serializer for creating a new user-defined tool.
│           Validates the structure of the 'definition' field.
│           """
│           class Meta:
│               model = Tool
│               fields = ['name', 'tool_type', 'definition']
│       
│           def validate_definition(self, value):
│               if not isinstance(value, dict):
│                   raise serializers.ValidationError("Definition must be a valid JSON object.")
│               if "name" not in value or "description" not in value or "parameters" not in value:
│                   raise serializers.ValidationError("Definition must contain 'name', 'description', and 'parameters' keys.")
│               if "execution" not in value:
│                   raise serializers.ValidationError("Definition must contain an 'execution' block.")
│               
│               execution_config = value.get("execution")
│               exec_type = execution_config.get("type")
│       
│               if exec_type == "webhook":
│                   if "url" not in execution_config:
│                       raise serializers.ValidationError("Webhook execution requires a 'url'.")
│               elif exec_type == "internal_function":
│                   # This is a system-level property and shouldn't be set by users.
│                   # We can add a check to prevent users from trying to create internal tools.
│                   raise serializers.ValidationError("User-defined tools cannot be of type 'internal_function'.")
│               else:
│                   raise serializers.ValidationError(f"Invalid execution type: '{exec_type}'. Must be 'webhook'.")
│                   
│               return value
│       
│       class ToolUpdateSerializer(ToolCreateSerializer):
│           """
│           Serializer for updating an existing user-defined tool.
│           Inherits validation from the create serializer.
│           """
│           pass
│   ]
│   services.py
│   [
│       # MS7/tools/services.py
│       import uuid
│       from django.db.models import Q, QuerySet
│       from .models import Tool
│       
│       class ToolService:
│           """
│           The service layer for handling all business logic related to Tool objects.
│           This separates the core logic from the view layer (HTTP request/response handling).
│           """
│       
│           def get_user_accessible_tools(self, user_id: uuid.UUID) -> QuerySet[Tool]:
│               """
│               Returns a queryset of all tools that a given user is allowed to see and use.
│               This includes all system tools plus the user's own private tools.
│       
│               Args:
│                   user_id: The UUID of the user making the request.
│       
│               Returns:
│                   A Django QuerySet containing the accessible Tool objects.
│               """
│               return Tool.objects.filter(
│                   Q(is_system_tool=True) | Q(owner_id=user_id)
│               )
│       
│           def get_tool_by_id_for_user(self, tool_id: uuid.UUID, user_id: uuid.UUID) -> Tool | None:
│               """
│               Retrieves a single tool by its ID, but only if the user has permission to access it.
│               This prevents one user from accessing another user's private tool via its ID.
│       
│               Args:
│                   tool_id: The UUID of the tool to retrieve.
│                   user_id: The UUID of the user making the request.
│       
│               Returns:
│                   The Tool object if found and accessible, otherwise None.
│               """
│               try:
│                   tool = self.get_user_accessible_tools(user_id).get(id=tool_id)
│                   return tool
│               except Tool.DoesNotExist:
│                   return None
│       
│           def create_user_tool(self, owner_id: uuid.UUID, name: str, tool_type: str, definition: dict) -> Tool:
│               """
│               Creates a new, private tool for a specific user.
│       
│               Args:
│                   owner_id: The UUID of the user who will own this tool.
│                   name: The programmatic name of the tool.
│                   tool_type: The type of the tool (e.g., 'standard').
│                   definition: The complete JSON definition for the tool.
│       
│               Returns:
│                   The newly created Tool object.
│               """
│               # The serializer should have already validated the data.
│               # This service method just handles the creation.
│               tool = Tool.objects.create(
│                   owner_id=owner_id,
│                   name=name,
│                   tool_type=tool_type,
│                   definition=definition,
│                   is_system_tool=False # User-created tools are never system tools
│               )
│               return tool
│   ]
│   ├───standard_tools
│   │   __init__.py
│   │   [
│   │       
│   │   ]
│   │   weather.py
│   │   [
│   │       import time
│   │       import random
│   │       
│   │       def get_current_weather(location: str) -> dict:
│   │           """Gets the current weather for a specific location."""
│   │           print(f"EXECUTING TOOL: get_current_weather with location='{location}'")
│   │           time.sleep(0.5) # Simulate network latency
│   │           conditions = ["Sunny", "Cloudy", "Rainy", "Windy"]
│   │           return {
│   │               "location": location,
│   │               "temperature": f"{random.randint(5, 35)}°C",
│   │               "condition": random.choice(conditions)
│   │           }
│   │   ]
│   tests.py
│   [
│       from django.test import TestCase
│       
│       # Create your tests here.
│       
│   ]
│   views.py
│   [
│       # MS7/tools/views.py
│       
│       import json
│       from django.conf import settings
│       import httpx
│       from rest_framework import generics, permissions, status
│       from rest_framework.response import Response
│       from rest_framework.exceptions import NotFound
│       
│       from .models import Tool
│       from .serializers import ToolSerializer, ToolCreateSerializer, ToolUpdateSerializer
│       from .permissions import IsOwner
│       from .services import ToolService # <-- Import the service
│       from messaging.event_publisher import tool_event_publisher  # Import the event publisher
│       class ToolListCreateAPIView(generics.ListCreateAPIView):
│           permission_classes = [permissions.IsAuthenticated]
│           
│           # --- Using the Service Layer ---
│           service = ToolService()
│       
│           def get_serializer_class(self):
│               if self.request.method == 'POST':
│                   return ToolCreateSerializer
│               return ToolSerializer
│       
│           def get_queryset(self):
│               """Delegates the logic for fetching accessible tools to the service layer."""
│               return self.service.get_user_accessible_tools(user_id=self.request.user.id)
│       
│           def perform_create(self, serializer):
│               """Delegates the creation logic to the service layer."""
│               self.service.create_user_tool(
│                   owner_id=self.request.user.id,
│                   **serializer.validated_data
│               )
│       
│       class ToolDetailAPIView(generics.RetrieveUpdateDestroyAPIView):
│           permission_classes = [permissions.IsAuthenticated, IsOwner]
│           
│           # --- Using the Service Layer ---
│           service = ToolService()
│       
│           def get_serializer_class(self):
│               if self.request.method in ['PUT', 'PATCH']:
│                   return ToolUpdateSerializer
│               return ToolSerializer
│       
│           def get_object(self):
│               """
│               Overrides the default get_object to use the service layer for
│               permission-aware retrieval.
│               """
│               tool_id = self.kwargs.get('pk')
│               user_id = self.request.user.id
│               
│               tool = self.service.get_tool_by_id_for_user(tool_id=tool_id, user_id=user_id)
│               
│               if not tool:
│                   raise NotFound("Tool not found or you do not have permission to access it.")
│               
│               # Check object-level write permissions (IsOwner) after retrieving
│               self.check_object_permissions(self.request, tool)
│               
│               return tool
│       
│           def destroy(self, request, *args, **kwargs):
│               instance = self.get_object()
│               tool_id_to_cleanup = str(instance.pk)
│               
│               # Perform deletion first
│               self.perform_destroy(instance)
│               
│               # Publish event
│               try:
│                   tool_event_publisher.publish_tool_deleted(tool_id=tool_id_to_cleanup)
│               except Exception as e:
│                   print(f"CRITICAL ALERT: Tool {tool_id_to_cleanup} was deleted, but event publishing failed: {e}")
│       
│               return Response(status=status.HTTP_204_NO_CONTENT)
│   ]
└───tools_internals
    __init__.py
    [
        
    ]
    admin.py
    [
        from django.contrib import admin
        
        # Register your models here.
        
    ]
    apps.py
    [
        from django.apps import AppConfig
        
        
        class ToolsInternalsConfig(AppConfig):
            default_auto_field = 'django.db.models.BigAutoField'
            name = 'tools_internals'
        
    ]
    ├───generated
    │   __init__.py
    │   [
    │       
    │   ]
    │   tool_pb2.py
    │   [
    │       # -*- coding: utf-8 -*-
    │       # Generated by the protocol buffer compiler.  DO NOT EDIT!
    │       # NO CHECKED-IN PROTOBUF GENCODE
    │       # source: tool.proto
    │       # Protobuf Python Version: 6.31.1
    │       """Generated protocol buffer code."""
    │       from google.protobuf import descriptor as _descriptor
    │       from google.protobuf import descriptor_pool as _descriptor_pool
    │       from google.protobuf import runtime_version as _runtime_version
    │       from google.protobuf import symbol_database as _symbol_database
    │       from google.protobuf.internal import builder as _builder
    │       _runtime_version.ValidateProtobufRuntimeVersion(
    │           _runtime_version.Domain.PUBLIC,
    │           6,
    │           31,
    │           1,
    │           '',
    │           'tool.proto'
    │       )
    │       # @@protoc_insertion_point(imports)
    │       
    │       _sym_db = _symbol_database.Default()
    │       
    │       
    │       from google.protobuf import struct_pb2 as google_dot_protobuf_dot_struct__pb2
    │       
    │       
    │       DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\ntool.proto\x12\x04tool\x1a\x1cgoogle/protobuf/struct.proto\"9\n\x14ValidateToolsRequest\x12\x0f\n\x07user_id\x18\x01 \x01(\t\x12\x10\n\x08tool_ids\x18\x02 \x03(\t\"B\n\x15ValidateToolsResponse\x12\x12\n\nauthorized\x18\x01 \x01(\x08\x12\x15\n\rerror_message\x18\x02 \x01(\t\">\n\x19GetToolDefinitionsRequest\x12\x0f\n\x07user_id\x18\x01 \x01(\t\x12\x10\n\x08tool_ids\x18\x02 \x03(\t\"J\n\x1aGetToolDefinitionsResponse\x12,\n\x0b\x64\x65\x66initions\x18\x01 \x03(\x0b\x32\x17.google.protobuf.Struct\"P\n\x08ToolCall\x12\n\n\x02id\x18\x01 \x01(\t\x12\x0c\n\x04name\x18\x02 \x01(\t\x12*\n\targuments\x18\x03 \x01(\x0b\x32\x17.google.protobuf.Struct\"A\n\x1b\x45xecuteMultipleToolsRequest\x12\"\n\ntool_calls\x18\x01 \x03(\x0b\x32\x0e.tool.ToolCall\"P\n\nToolResult\x12\x14\n\x0ctool_call_id\x18\x01 \x01(\t\x12\x0c\n\x04name\x18\x02 \x01(\t\x12\x0e\n\x06status\x18\x03 \x01(\t\x12\x0e\n\x06output\x18\x04 \x01(\t\"A\n\x1c\x45xecuteMultipleToolsResponse\x12!\n\x07results\x18\x01 \x03(\x0b\x32\x10.tool.ToolResult2\x8f\x02\n\x0bToolService\x12H\n\rValidateTools\x12\x1a.tool.ValidateToolsRequest\x1a\x1b.tool.ValidateToolsResponse\x12W\n\x12GetToolDefinitions\x12\x1f.tool.GetToolDefinitionsRequest\x1a .tool.GetToolDefinitionsResponse\x12]\n\x14\x45xecuteMultipleTools\x12!.tool.ExecuteMultipleToolsRequest\x1a\".tool.ExecuteMultipleToolsResponseb\x06proto3')
    │       
    │       _globals = globals()
    │       _builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
    │       _builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'tool_pb2', _globals)
    │       if not _descriptor._USE_C_DESCRIPTORS:
    │         DESCRIPTOR._loaded_options = None
    │         _globals['_VALIDATETOOLSREQUEST']._serialized_start=50
    │         _globals['_VALIDATETOOLSREQUEST']._serialized_end=107
    │         _globals['_VALIDATETOOLSRESPONSE']._serialized_start=109
    │         _globals['_VALIDATETOOLSRESPONSE']._serialized_end=175
    │         _globals['_GETTOOLDEFINITIONSREQUEST']._serialized_start=177
    │         _globals['_GETTOOLDEFINITIONSREQUEST']._serialized_end=239
    │         _globals['_GETTOOLDEFINITIONSRESPONSE']._serialized_start=241
    │         _globals['_GETTOOLDEFINITIONSRESPONSE']._serialized_end=315
    │         _globals['_TOOLCALL']._serialized_start=317
    │         _globals['_TOOLCALL']._serialized_end=397
    │         _globals['_EXECUTEMULTIPLETOOLSREQUEST']._serialized_start=399
    │         _globals['_EXECUTEMULTIPLETOOLSREQUEST']._serialized_end=464
    │         _globals['_TOOLRESULT']._serialized_start=466
    │         _globals['_TOOLRESULT']._serialized_end=546
    │         _globals['_EXECUTEMULTIPLETOOLSRESPONSE']._serialized_start=548
    │         _globals['_EXECUTEMULTIPLETOOLSRESPONSE']._serialized_end=613
    │         _globals['_TOOLSERVICE']._serialized_start=616
    │         _globals['_TOOLSERVICE']._serialized_end=887
    │       # @@protoc_insertion_point(module_scope)
    │       
    │   ]
    │   tool_pb2_grpc.py
    │   [
    │       # Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
    │       """Client and server classes corresponding to protobuf-defined services."""
    │       import grpc
    │       import warnings
    │       
    │       from . import tool_pb2 as tool__pb2
    │       
    │       GRPC_GENERATED_VERSION = '1.74.0'
    │       GRPC_VERSION = grpc.__version__
    │       _version_not_supported = False
    │       
    │       try:
    │           from grpc._utilities import first_version_is_lower
    │           _version_not_supported = first_version_is_lower(GRPC_VERSION, GRPC_GENERATED_VERSION)
    │       except ImportError:
    │           _version_not_supported = True
    │       
    │       if _version_not_supported:
    │           raise RuntimeError(
    │               f'The grpc package installed is at version {GRPC_VERSION},'
    │               + f' but the generated code in tool_pb2_grpc.py depends on'
    │               + f' grpcio>={GRPC_GENERATED_VERSION}.'
    │               + f' Please upgrade your grpc module to grpcio>={GRPC_GENERATED_VERSION}'
    │               + f' or downgrade your generated code using grpcio-tools<={GRPC_VERSION}.'
    │           )
    │       
    │       
    │       class ToolServiceStub(object):
    │           """Missing associated documentation comment in .proto file."""
    │       
    │           def __init__(self, channel):
    │               """Constructor.
    │       
    │               Args:
    │                   channel: A grpc.Channel.
    │               """
    │               self.ValidateTools = channel.unary_unary(
    │                       '/tool.ToolService/ValidateTools',
    │                       request_serializer=tool__pb2.ValidateToolsRequest.SerializeToString,
    │                       response_deserializer=tool__pb2.ValidateToolsResponse.FromString,
    │                       _registered_method=True)
    │               self.GetToolDefinitions = channel.unary_unary(
    │                       '/tool.ToolService/GetToolDefinitions',
    │                       request_serializer=tool__pb2.GetToolDefinitionsRequest.SerializeToString,
    │                       response_deserializer=tool__pb2.GetToolDefinitionsResponse.FromString,
    │                       _registered_method=True)
    │               self.ExecuteMultipleTools = channel.unary_unary(
    │                       '/tool.ToolService/ExecuteMultipleTools',
    │                       request_serializer=tool__pb2.ExecuteMultipleToolsRequest.SerializeToString,
    │                       response_deserializer=tool__pb2.ExecuteMultipleToolsResponse.FromString,
    │                       _registered_method=True)
    │       
    │       
    │       class ToolServiceServicer(object):
    │           """Missing associated documentation comment in .proto file."""
    │       
    │           def ValidateTools(self, request, context):
    │               """For Node Service: Validates if a user can access a list of tools.
    │               Note: This is also implemented as an HTTP endpoint for services that prefer REST.
    │               """
    │               context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    │               context.set_details('Method not implemented!')
    │               raise NotImplementedError('Method not implemented!')
    │       
    │           def GetToolDefinitions(self, request, context):
    │               """For Inference P1: Fetches the full definitions for a list of tools.
    │               """
    │               context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    │               context.set_details('Method not implemented!')
    │               raise NotImplementedError('Method not implemented!')
    │       
    │           def ExecuteMultipleTools(self, request, context):
    │               """For Inference P2: Executes one or more tool calls in parallel.
    │               """
    │               context.set_code(grpc.StatusCode.UNIMPLEMENTED)
    │               context.set_details('Method not implemented!')
    │               raise NotImplementedError('Method not implemented!')
    │       
    │       
    │       def add_ToolServiceServicer_to_server(servicer, server):
    │           rpc_method_handlers = {
    │                   'ValidateTools': grpc.unary_unary_rpc_method_handler(
    │                           servicer.ValidateTools,
    │                           request_deserializer=tool__pb2.ValidateToolsRequest.FromString,
    │                           response_serializer=tool__pb2.ValidateToolsResponse.SerializeToString,
    │                   ),
    │                   'GetToolDefinitions': grpc.unary_unary_rpc_method_handler(
    │                           servicer.GetToolDefinitions,
    │                           request_deserializer=tool__pb2.GetToolDefinitionsRequest.FromString,
    │                           response_serializer=tool__pb2.GetToolDefinitionsResponse.SerializeToString,
    │                   ),
    │                   'ExecuteMultipleTools': grpc.unary_unary_rpc_method_handler(
    │                           servicer.ExecuteMultipleTools,
    │                           request_deserializer=tool__pb2.ExecuteMultipleToolsRequest.FromString,
    │                           response_serializer=tool__pb2.ExecuteMultipleToolsResponse.SerializeToString,
    │                   ),
    │           }
    │           generic_handler = grpc.method_handlers_generic_handler(
    │                   'tool.ToolService', rpc_method_handlers)
    │           server.add_generic_rpc_handlers((generic_handler,))
    │           server.add_registered_method_handlers('tool.ToolService', rpc_method_handlers)
    │       
    │       
    │        # This class is part of an EXPERIMENTAL API.
    │       class ToolService(object):
    │           """Missing associated documentation comment in .proto file."""
    │       
    │           @staticmethod
    │           def ValidateTools(request,
    │                   target,
    │                   options=(),
    │                   channel_credentials=None,
    │                   call_credentials=None,
    │                   insecure=False,
    │                   compression=None,
    │                   wait_for_ready=None,
    │                   timeout=None,
    │                   metadata=None):
    │               return grpc.experimental.unary_unary(
    │                   request,
    │                   target,
    │                   '/tool.ToolService/ValidateTools',
    │                   tool__pb2.ValidateToolsRequest.SerializeToString,
    │                   tool__pb2.ValidateToolsResponse.FromString,
    │                   options,
    │                   channel_credentials,
    │                   insecure,
    │                   call_credentials,
    │                   compression,
    │                   wait_for_ready,
    │                   timeout,
    │                   metadata,
    │                   _registered_method=True)
    │       
    │           @staticmethod
    │           def GetToolDefinitions(request,
    │                   target,
    │                   options=(),
    │                   channel_credentials=None,
    │                   call_credentials=None,
    │                   insecure=False,
    │                   compression=None,
    │                   wait_for_ready=None,
    │                   timeout=None,
    │                   metadata=None):
    │               return grpc.experimental.unary_unary(
    │                   request,
    │                   target,
    │                   '/tool.ToolService/GetToolDefinitions',
    │                   tool__pb2.GetToolDefinitionsRequest.SerializeToString,
    │                   tool__pb2.GetToolDefinitionsResponse.FromString,
    │                   options,
    │                   channel_credentials,
    │                   insecure,
    │                   call_credentials,
    │                   compression,
    │                   wait_for_ready,
    │                   timeout,
    │                   metadata,
    │                   _registered_method=True)
    │       
    │           @staticmethod
    │           def ExecuteMultipleTools(request,
    │                   target,
    │                   options=(),
    │                   channel_credentials=None,
    │                   call_credentials=None,
    │                   insecure=False,
    │                   compression=None,
    │                   wait_for_ready=None,
    │                   timeout=None,
    │                   metadata=None):
    │               return grpc.experimental.unary_unary(
    │                   request,
    │                   target,
    │                   '/tool.ToolService/ExecuteMultipleTools',
    │                   tool__pb2.ExecuteMultipleToolsRequest.SerializeToString,
    │                   tool__pb2.ExecuteMultipleToolsResponse.FromString,
    │                   options,
    │                   channel_credentials,
    │                   insecure,
    │                   call_credentials,
    │                   compression,
    │                   wait_for_ready,
    │                   timeout,
    │                   metadata,
    │                   _registered_method=True)
    │       
    │   ]
    internal_urls.py
    [
        from django.urls import path
        from .internal_views import ValidateToolsAPIView
        
        urlpatterns = [
            # Endpoint for the Node Service to call via HTTP
            path('tools/validate/', ValidateToolsAPIView.as_view(), name='internal-tool-validate'),
        ]
    ]
    internal_views.py
    [
        from django.shortcuts import render
        
        # Create your views here.
        from rest_framework.views import APIView
        from rest_framework.response import Response
        from rest_framework import status, permissions
        from django.db.models import Q
        from tools.models import Tool
        import uuid
        
        class ValidateToolsAPIView(APIView):
            """
            Internal HTTP endpoint for the Node Service to validate tool ownership
            before creating or updating a node. Mirrors the gRPC ValidateTools logic.
            """
            permission_classes = [permissions.IsAuthenticated]
        
            def post(self, request):
                user_id = request.user.id
                tool_ids_str = request.data.get('tool_ids', [])
        
                if not isinstance(tool_ids_str, list):
                    return Response({"error": "'tool_ids' must be a list."}, status=status.HTTP_400_BAD_REQUEST)
                
                try:
                    tool_ids = [uuid.UUID(tid) for tid in tool_ids_str]
                except (ValueError, TypeError):
                    return Response({"error": "One or more tool IDs are not valid UUIDs."}, status=status.HTTP_400_BAD_REQUEST)
        
                if not tool_ids:
                    return Response(status=status.HTTP_204_NO_CONTENT)
        
                valid_tool_count = Tool.objects.filter(
                    Q(is_system_tool=True) | Q(owner_id=user_id),
                    id__in=tool_ids
                ).count()
        
                if valid_tool_count == len(tool_ids):
                    return Response(status=status.HTTP_204_NO_CONTENT)
                else:
                    return Response(
                        {"error": "One or more tool IDs are invalid or you do not have permission to use them."},
                        status=status.HTTP_403_FORBIDDEN
                    )
    ]
    ├───management
    │   └───commands
    │       generate_protos.py
    │       [
    │           import os
    │           import subprocess
    │           import fileinput
    │           from django.core.management.base import BaseCommand
    │           
    │           class Command(BaseCommand):
    │               help = 'Generates Python gRPC code from .proto files.'
    │               requires_system_checks = [] # Prevents Django app checks from running
    │           
    │               def handle(self, *args, **options):
    │                   proto_path = 'tools_internals/protos'
    │                   output_path = 'tools_internals/generated'
    │                   
    │                   if not os.path.exists(proto_path):
    │                       self.stderr.write(self.style.ERROR(f"Proto path '{proto_path}' does not exist."))
    │                       return
    │                   
    │                   os.makedirs(output_path, exist_ok=True)
    │                   open(os.path.join(output_path, '__init__.py'), 'a').close()
    │           
    │                   proto_files = [f for f in os.listdir(proto_path) if f.endswith('.proto')]
    │                   if not proto_files:
    │                       self.stdout.write(self.style.WARNING('No .proto files found.'))
    │                       return
    │                       
    │                   command = [
    │                       'python', '-m', 'grpc_tools.protoc',
    │                       f'--proto_path={proto_path}',
    │                       f'--python_out={output_path}',
    │                       f'--grpc_python_out={output_path}',
    │                   ] + proto_files
    │           
    │                   self.stdout.write(f"Running command: {' '.join(command)}")
    │                   try:
    │                       subprocess.run(command, check=True, capture_output=True, text=True)
    │                       self.stdout.write(self.style.SUCCESS('Successfully generated gRPC Python stubs.'))
    │                       
    │                       for proto_file in proto_files:
    │                           base_name = proto_file.replace('.proto', '')
    │                           grpc_file_path = os.path.join(output_path, f'{base_name}_pb2_grpc.py')
    │                           
    │                           self.stdout.write(f"Fixing imports in {grpc_file_path}...")
    │                           with fileinput.FileInput(grpc_file_path, inplace=True) as file:
    │                               for line in file:
    │                                   if line.strip() == f'import {base_name}_pb2 as {base_name}__pb2':
    │                                       print(f'from . import {base_name}_pb2 as {base_name}__pb2')
    │                                   else:
    │                                       print(line, end='')
    │                           self.stdout.write(self.style.SUCCESS('Imports fixed.'))
    │                   except subprocess.CalledProcessError as e:
    │                       self.stderr.write(self.style.ERROR(f'Failed to generate gRPC stubs: {e.stderr}'))
    │       ]
    │       run_grpc_server.py
    │       [
    │           import grpc
    │           from concurrent import futures
    │           import time
    │           from django.core.management.base import BaseCommand
    │           import django
    │           import os
    │           
    │           # Setup Django before importing models and services
    │           os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'ms7_project.settings')
    │           django.setup()
    │           
    │           from tools_internals.generated import tool_pb2_grpc
    │           from tools_internals.servicer import ToolServicer
    │           
    │           class Command(BaseCommand):
    │               help = 'Starts the gRPC server for the Tool Service'
    │           
    │               def handle(self, *args, **options):
    │                   port = '50057'
    │                   self.stdout.write(f"Starting Tool Service gRPC server on port {port}...")
    │                   
    │                   server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    │                   
    │                   tool_pb2_grpc.add_ToolServiceServicer_to_server(ToolServicer(), server)
    │                   
    │                   server.add_insecure_port(f'[::]:{port}')
    │                   server.start()
    │                   self.stdout.write(self.style.SUCCESS(f'Tool Service gRPC server started successfully on port {port}.'))
    │                   
    │                   try:
    │                       while True:
    │                           time.sleep(86400) # Sleep for a day
    │                   except KeyboardInterrupt:
    │                       self.stdout.write(self.style.WARNING('Stopping gRPC server...'))
    │                       server.stop(0)
    │       ]
    models.py
    [
        from django.db import models
        
        # Create your models here.
        
    ]
    ├───protos
    │   tool.proto
    │   [
    │       syntax = "proto3";
    │       
    │       import "google/protobuf/struct.proto";
    │       
    │       package tool;
    │       
    │       service ToolService {
    │         // For Node Service: Validates if a user can access a list of tools.
    │         // Note: This is also implemented as an HTTP endpoint for services that prefer REST.
    │         rpc ValidateTools(ValidateToolsRequest) returns (ValidateToolsResponse);
    │       
    │         // For Inference P1: Fetches the full definitions for a list of tools.
    │         rpc GetToolDefinitions(GetToolDefinitionsRequest) returns (GetToolDefinitionsResponse);
    │         
    │         // For Inference P2: Executes one or more tool calls in parallel.
    │         rpc ExecuteMultipleTools(ExecuteMultipleToolsRequest) returns (ExecuteMultipleToolsResponse);
    │       }
    │       
    │       // --- Messages for Validation ---
    │       message ValidateToolsRequest {
    │         string user_id = 1;
    │         repeated string tool_ids = 2;
    │       }
    │       message ValidateToolsResponse {
    │         bool authorized = 1;
    │         string error_message = 2;
    │       }
    │       
    │       // --- Messages for Definition Fetching ---
    │       message GetToolDefinitionsRequest {
    │         string user_id = 1;
    │         repeated string tool_ids = 2;
    │       }
    │       message GetToolDefinitionsResponse {
    │         repeated google.protobuf.Struct definitions = 1;
    │       }
    │       
    │       // --- Messages for Execution ---
    │       message ToolCall {
    │           string id = 1; // ID from the LLM to track the call
    │           string name = 2;
    │           google.protobuf.Struct arguments = 3;
    │       }
    │       message ExecuteMultipleToolsRequest {
    │         repeated ToolCall tool_calls = 1;
    │       }
    │       
    │       message ToolResult {
    │           string tool_call_id = 1;
    │           string name = 2;
    │           string status = 3; // "success" or "error"
    │           string output = 4; // The JSON string result of the tool execution
    │       }
    │       message ExecuteMultipleToolsResponse {
    │           repeated ToolResult results = 1;
    │       }
    │   ]
    servicer.py
    [
        import grpc
        from google.protobuf.struct_pb2 import Struct
        from django.db.models import Q
        import uuid
        import logging
        
        from .generated import tool_pb2, tool_pb2_grpc
        from tools.models import Tool
        from tools.executor import tool_executor
        
        # Configure a logger for this servicer
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - MS7-gRPC - %(levelname)s - %(message)s')
        logger = logging.getLogger(__name__)
        
        class ToolServicer(tool_pb2_grpc.ToolServiceServicer):
            """
            Implements the gRPC service methods for the Tool Service.
            This class is the bridge between gRPC requests and the core application logic.
            """
        
            def ValidateTools(self, request, context):
                logger.info(f"Received ValidateTools request for user '{request.user_id}' with {len(request.tool_ids)} tool(s).")
                try:
                    user_id = uuid.UUID(request.user_id)
                    tool_ids = [uuid.UUID(tid) for tid in request.tool_ids]
                except ValueError:
                    logger.warning("Invalid UUID format in ValidateTools request.")
                    context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                    context.set_details("Invalid UUID format for user_id or tool_ids.")
                    return tool_pb2.ValidateToolsResponse()
        
                if not tool_ids:
                    logger.info("ValidateTools request had no tool IDs. Returning authorized.")
                    return tool_pb2.ValidateToolsResponse(authorized=True)
        
                valid_tool_count = Tool.objects.filter(
                    Q(is_system_tool=True) | Q(owner_id=user_id),
                    id__in=tool_ids
                ).count()
        
                if valid_tool_count == len(tool_ids):
                    logger.info(f"Successfully validated {len(tool_ids)} tools for user '{user_id}'.")
                    return tool_pb2.ValidateToolsResponse(authorized=True)
                else:
                    error_msg = "One or more tool IDs are invalid or you do not have permission to use them."
                    logger.warning(f"Permission denied for user '{user_id}' on tool validation: {error_msg}")
                    context.set_code(grpc.StatusCode.PERMISSION_DENIED)
                    context.set_details(error_msg)
                    return tool_pb2.ValidateToolsResponse(authorized=False, error_message=error_msg)
        
            def GetToolDefinitions(self, request, context):
                logger.info(f"Received GetToolDefinitions request for user '{request.user_id}' with {len(request.tool_ids)} tool(s).")
                try:
                    user_id = uuid.UUID(request.user_id)
                    tool_ids = [uuid.UUID(tid) for tid in request.tool_ids]
                except ValueError:
                    logger.warning("Invalid UUID format in GetToolDefinitions request.")
                    context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                    context.set_details("Invalid UUID format for user_id or tool_ids.")
                    return tool_pb2.GetToolDefinitionsResponse()
        
                accessible_tools = Tool.objects.filter(
                    Q(is_system_tool=True) | Q(owner_id=user_id),
                    id__in=tool_ids
                )
        
                if accessible_tools.count() != len(tool_ids):
                    error_msg = "Could not find all requested tools or permission denied for one or more tools."
                    logger.warning(f"Not found or permission denied during GetToolDefinitions: {error_msg}")
                    context.set_code(grpc.StatusCode.NOT_FOUND)
                    context.set_details(error_msg)
                    return tool_pb2.GetToolDefinitionsResponse()
        
                definitions = [tool.definition for tool in accessible_tools]
                
                proto_definitions = []
                for definition_dict in definitions:
                    s = Struct()
                    s.update(definition_dict)
                    proto_definitions.append(s)
        
                logger.info(f"Successfully found and returning {len(proto_definitions)} tool definitions.")
                return tool_pb2.GetToolDefinitionsResponse(definitions=proto_definitions)
        
            def ExecuteMultipleTools(self, request, context):
                logger.info(f"Received ExecuteMultipleTools request for {len(request.tool_calls)} tool call(s).")
                try:
                    tool_calls_list = []
                    for call in request.tool_calls:
                        arguments = dict(call.arguments) if call.arguments else {}
                        tool_calls_list.append({
                            'id': call.id,
                            'name': call.name,
                            'arguments': arguments
                        })
                    
                    # Delegate to the robust, parallel executor
                    results = tool_executor.execute_parallel_tools(tool_calls_list)
                    
                    proto_results = [tool_pb2.ToolResult(**res) for res in results]
                    logger.info(f"Successfully executed {len(proto_results)} tool(s).")
                    return tool_pb2.ExecuteMultipleToolsResponse(results=proto_results)
                except Exception as e:
                    logger.error(f"INTERNAL ERROR during ExecuteMultipleTools: {e}", exc_info=True)
                    context.set_code(grpc.StatusCode.INTERNAL)
                    context.set_details('An internal error occurred in the Tool Service executor.')
                    return tool_pb2.ExecuteMultipleToolsResponse()
    ]
